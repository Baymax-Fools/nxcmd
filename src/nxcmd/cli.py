# src/nxcmd/cli.py
import sys
import json
from pathlib import Path
from .model import LocalWorldModel


def get_recent_commands(n=2):
    """ä»æ—¥å¿—æœ«å°¾è¯»å–æœ€è¿‘ n æ¡å‘½ä»¤ï¼ˆæ’é™¤ nextcmd è‡ªèº«ï¼‰"""
    log_path = Path("~/.wm_shell/history.jsonl").expanduser()
    if not log_path.exists():
        return []
    
    recent = []
    with open(log_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # ä»åå¾€å‰æ‰¾æœ‰æ•ˆå‘½ä»¤
    for line in reversed(lines):
        try:
            record = json.loads(line.strip())
            cmd = record["cmd"].strip()
            # ä½¿ç”¨ä¸æ¨¡å‹ç›¸åŒçš„æ¸…ç†é€»è¾‘
            cleaned_cmd = clean_command(cmd)
            if cleaned_cmd and "nextcmd" not in cmd and "main.py" not in cmd:
                recent.append(cleaned_cmd)
                if len(recent) >= n:
                    break
        except:
            continue
    
    return list(reversed(recent))  # ä¿æŒæ—¶é—´é¡ºåº

def clean_command(raw_cmd):
    """æ¸…ç†å‘½ä»¤ï¼šç§»é™¤å†å²ç¼–å·å’Œå¤šä½™ç©ºæ ¼ï¼ˆä¸æ¨¡å‹ä¸­çš„é€»è¾‘ä¿æŒä¸€è‡´ï¼‰"""
    parts = raw_cmd.split()
    if parts and parts[0].isdigit() and len(parts) > 1:
        cleaned = ' '.join(parts[1:])
    else:
        cleaned = raw_cmd
    return ' '.join(cleaned.split())

def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    print("""
ğŸ”® NxCmd - æ™ºèƒ½å‘½ä»¤é¢„æµ‹å·¥å…·

ä½¿ç”¨æ–¹æ³•:
  nxcmd suggest      # åŸºäºæœ€è¿‘å‘½ä»¤é¢„æµ‹ä¸‹ä¸€ä¸ªå¯èƒ½å‘½ä»¤
  nxcmd simulate <cmd>  # æ¨¡æ‹Ÿåœ¨æŒ‡å®šå‘½ä»¤åçš„é¢„æµ‹
  nxcmd stats       # æ˜¾ç¤ºæ¨¡å‹ç»Ÿè®¡ä¿¡æ¯
  nxcmd demo        # è¿è¡Œæ¼”ç¤ºæ¨¡å¼
  nxcmd help        # æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

ç¤ºä¾‹:
  nxcmd suggest
  nxcmd simulate "git add"
  nxcmd stats
    """)

def run_demo(model):
    """æ¼”ç¤ºæ¨¡å¼ï¼šå±•ç¤ºæ¨¡å‹åŠŸèƒ½"""
    print("=== NextCmd æ¼”ç¤ºæ¨¡å¼ ===")
    
    print("\nğŸ“Š æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯:")
    model.get_command_stats()
    
    print("\nğŸ¯ å­¦ä¹ åˆ°çš„å‘½ä»¤æ¨¡å¼:")
    model.debug_transitions()
    
    # æµ‹è¯•å‡ ä¸ªå¸¸è§çš„é¢„æµ‹åœºæ™¯
    test_cases = [
        ['git', 'add'],
        ['cd', '~'],
        ['ls', '-la']
    ]
    
    print("\nğŸ§ª é¢„æµ‹æµ‹è¯•:")
    for context in test_cases:
        predictions = model.predict_next(context, top_k=3)
        if predictions:
            print(f"åœ¨å‘½ä»¤ {' â†’ '.join(context)} åï¼Œå¯èƒ½æ‰§è¡Œ:")
            for cmd, count in predictions:
                print(f"  - {cmd} ({count}æ¬¡)")
        else:
            print(f"åœ¨å‘½ä»¤ {' â†’ '.join(context)} å: æ— é¢„æµ‹ç»“æœ")
        print()

def main():
    """CLI ä¸»å…¥å£å‡½æ•°"""
    if len(sys.argv) < 2 or sys.argv[1] in ['help', '--help', '-h']:
        show_help()
        return

    # åˆå§‹åŒ–å¹¶è®­ç»ƒæ¨¡å‹
    model = LocalWorldModel()
    print("ğŸ”® åŠ è½½å‘½ä»¤å†å²å¹¶è®­ç»ƒæ¨¡å‹...")
    model.load_and_train()

    command = sys.argv[1]

    if command == "suggest":
        recent = get_recent_commands(n=2)
        if not recent:
            print("â„¹ï¸  æœªæ‰¾åˆ°æœ€è¿‘çš„å‘½ä»¤ã€‚è¯·å…ˆåœ¨ç»ˆç«¯ä¸­ä½¿ç”¨ä¸€äº›å‘½ä»¤ï¼")
            print("   å°è¯•ä½¿ç”¨: ls, cd, git status ç­‰å‘½ä»¤ï¼Œç„¶åå†æ¬¡è¿è¡Œã€‚")
            return

        print(f"ğŸ§  åŸºäºæœ€è¿‘å‘½ä»¤: {' â†’ '.join(recent)}")
        
        # ä½¿ç”¨æ¨¡å‹çš„é¢„æµ‹æ–¹æ³•
        suggestions = model.predict_next(recent, top_k=5)
        
        if suggestions:
            print("ğŸ’¡ å»ºè®®çš„ä¸‹ä¸€ä¸ªå‘½ä»¤:")
            for i, (cmd, count) in enumerate(suggestions, 1):
                print(f"  {i}. {cmd} (å‡ºç° {count} æ¬¡)")
        else:
            print("ğŸ¤” æœªæ‰¾åˆ°å»ºè®®ã€‚å°è¯•ä½¿ç”¨æ›´å¤šå‘½ä»¤æ¥ä¸°å¯Œæ¨¡å‹ï¼")
            print("   æˆ–è€…ä½¿ç”¨ 'nextcmd simulate <ä½ çš„å‘½ä»¤>' æ¥æµ‹è¯•ç‰¹å®šå‘½ä»¤")

    elif command == "simulate":
        if len(sys.argv) < 3:
            print("âŒ è¯·æä¾›è¦æ¨¡æ‹Ÿçš„å‘½ä»¤")
            print("   ä¾‹å¦‚: nextcmd simulate 'git add'")
            print("   ä¾‹å¦‚: nextcmd simulate 'cd projects' 'ls'")
            sys.exit(1)
        
        # æ”¯æŒå¤šä¸ªä¸Šä¸‹æ–‡å‘½ä»¤
        context_commands = []
        for i in range(2, len(sys.argv)):
            cmd = clean_command(sys.argv[i])
            context_commands.append(cmd)
        
        print(f"ğŸ”® æ¨¡æ‹Ÿå‘½ä»¤å: {' â†’ '.join(context_commands)}")
        suggestions = model.predict_next(context_commands, top_k=5)
        
        if suggestions:
            print("ğŸ’¡ å¸¸è§çš„åç»­å‘½ä»¤:")
            for i, (cmd, count) in enumerate(suggestions, 1):
                print(f"  {i}. {cmd} (å‡ºç° {count} æ¬¡)")
        else:
            print("ğŸ¤” æœªæ‰¾åˆ°å¸¸è§çš„åç»­å‘½ä»¤ã€‚")

    elif command == "stats":
        # æ˜¾ç¤ºæ¨¡å‹ç»Ÿè®¡ä¿¡æ¯
        model.get_command_stats()
        print("\nğŸ“Š æœ€è¿‘å­¦åˆ°çš„æ¨¡å¼:")
        model.debug_transitions()

    elif command == "demo":
        # è¿è¡Œæ¼”ç¤ºæ¨¡å¼
        run_demo(model)

    else:
        print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")
        show_help()
        sys.exit(1)

if __name__ == "__main__":
    main()